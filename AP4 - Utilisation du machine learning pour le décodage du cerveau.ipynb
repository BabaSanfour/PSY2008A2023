{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation du machine learning pour le décodage du cerveau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- extraction de features?\n",
    "- selection algo\n",
    "    * LDA, SVM, Arbres...\n",
    "    * En fonction de la taille et de la forme des données.\n",
    "- selection du design de l'expérience\n",
    "    * Intra-sujets (BCI).\n",
    "    * inter-sujets recherche plus fondamentale.\n",
    "    * K-Fold, stratified K-fold, Leave-one-out, leave-p-out, stratified leave-p-out.\n",
    "    * métrique utilisée pour évaluer le modèle.\n",
    "- evaluation du resultat\n",
    "    * Visualisations (matrices de confusion, topomaps)\n",
    "    * Test de permutations\n",
    "    * corrections statistiques\n",
    "- Bonus\n",
    "    * Optimisation hyper-paramètres\n",
    "    * Multi-features\n",
    "    * Deep learning -> se passer de la l'extraction de caractéristiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition du problème\n",
    "\n",
    "Avant de se lancer directement dans les données, il faut déjà savoir quelles caractéristiques du signal on compte utiliser et choisir un modèle adapté.\n",
    "\n",
    "Tout les algorithmes d'apprentissage automatique ne sont pas égaux face à différents jeux de données. Par exemple, les forêts et arbres de classification sont plus efficaces sur des données avec beaucoup de caractéristiques que les SVM qui souffriront bien plus du fléau de la dimensionalité.\n",
    "\n",
    "Il faut aussi se demander si la quantité de données est suffisante pour l'hypothèse que l'on veut vérifier. Même si on peut parfois utiliser des tests statistiques pour valider un résultat obtenu avec peu de données. Comme en neuroscience, les données dont souvent coûteuses et donc souvent peu nombreuses il n'est pas rare de devoir avoir recours à de l'augmentation de données pour y pallier.\n",
    "\n",
    "Dans le cas présent, nous allons explorer différents designs pour essayer de résoudre différents problèmes sur un même jeu de données.\n",
    "\n",
    "Pour se faire, on va utiliser la librairie <a href=\"\">sklearn</a> qui va nous permettre d'utiliser certains algorithmes d'apprentissagge machine assez simplement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des librairies nécessaires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, LeaveOneGroupOut, LeavePGroupsOut, StratifiedKFold\n",
    "from sklearn.svm import SVC as SVM\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problème 1: Classification gauche-droite\n",
    "\n",
    "Premièrement nous allons nous intéresser à effectuer une classification de nos données qui nous permettra de détecter si le sujet à entendu un stimulus à gauche ou bien à droite. Dans une approche guidée par les données (data driven), nous n'allons pas émetre d'hypothèse au préalable sur les résultats. \n",
    "\n",
    "On va, pour chaque capteur, essayer de faire la différence entre stimulus gauche et stimulus droit, en utilisant les valeurs de PSD calculées dans l'AP3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données\n",
    "\n",
    "Les classifications sont des méthodes d'apprentissage machine dites supervisées et nécessitent l'utilisation de deux matrices:\n",
    "- une matrice data souvent appelée X, qui contient les données que l'on va utiliser pour l'apprentissage et le test de l'algorithme d'apprentissage machine.\n",
    "- Une matrice \"labels\" ou \"targets\" souvent appelée y, qui contient l'information que l'on souhaite prédire encodée en chiffres.\n",
    "\n",
    "Dans notre exemple, comme nous souhaitons classifier entre stimulus gauche ou droite, on va arbitrairement associer 0 ou 1 à chacune de nos classes. Par exemple: 0 <=> gauche ; 1 <=> droite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['visualleft', 'visualright']\n",
    "# data_path = mne.datasets.sample.data_path()\n",
    "data_path = \"/home/arthur/Downloads/\"\n",
    "data = []\n",
    "targets = []\n",
    "for i, condition in enumerate(conditions):\n",
    "#     temp_data = np.load(op.join(data_path, 'MEG', 'sample', f'{condition}_psds_bands'))\n",
    "    temp_data = np.load(op.join(data_path, f'{condition}_psds_bands.npy'))\n",
    "    targets += [i]*temp_data.shape[1]\n",
    "    data.append(temp_data)\n",
    "\n",
    "X = np.concatenate(data, axis=1)\n",
    "y = np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix de l'algorithme\n",
    "\n",
    "Pour commencer, nous allons utiliser K Nearest Neighbors (KNN). Un algorithms simple, rapide en exécution qui possède un seul hyper-paramètre.\n",
    "\n",
    "Pour le moment, on va évaluer les performances de l'algorithme sans se soucier d'optimiser les hyper-paramètres, mais on reviendra sur ce concept plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix de la méthode de validation\n",
    "\n",
    "Il nous faut maintenant choisir une méthode qui nous permettra de mieux évaluer les performances de notre algorithme. Le choix de cette méthode est important car si la méthode de validation est mal choisie, elle pourrait impacter nos résultats. \n",
    "\n",
    "Cette méthode va dicter la façon dont on va séparer nos données afin d'entraîner notre algorithme sur une partie et de tester sur une autre. Elle est nécessaire car sans elle, nous ne pourrions pas controller le sur-apprentissage (overfitting).\n",
    "\n",
    "La méthode la plus simple qui existe est de séparer nos données en deux partie: entraînement (train) et validation ou test ce que l'on appelle la \"Holdout method\":\n",
    "\n",
    "Coupons arbitrairemement les données en 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:72]\n",
    "y_train = y[:72]\n",
    "\n",
    "X_test = X[72:]\n",
    "y_test = y[72:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immédiatement, si on affiche les labels de nos données on se rend compte d'un problème: notre sous-ensemble d'etraaînement ne contient que des exemples de stimuli à gauche et sera donc incapable d'apprendre comment différentier droite de gauche!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut donc prendre au hasard des exemples du jeu de données initial ou encore le mélanger avant de tirer les exemples.\n",
    "\n",
    "Pour ce faire, on créé un index des données sur lequel on va effectuer le mélange afin de pouvoir effectuer exactement le même mélamge sur les labels. Sans quoi on perdrait la correspondance entre exemple et sa catégorie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 1 0 0 1 1 1 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 1 1\n",
      " 1 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Création de l'index:\n",
    "index = np.arange(X.shape[1])\n",
    "\n",
    "# mélange de l'index:\n",
    "np.random.shuffle(index)\n",
    "\n",
    "# On applique le mélange aux données et aux labels:\n",
    "shuffled_X = X[index]\n",
    "shuffled_y = y[index]\n",
    "\n",
    "# On effectue notre séparation (split) à nouveau:\n",
    "X_train = shuffled_X[:72]\n",
    "y_train = shuffled_y[:72]\n",
    "\n",
    "X_test = shuffled_X[72:]\n",
    "y_test = shuffled_y[72:]\n",
    "\n",
    "# Affichons à nouveau nos labels d'entraînement pour vérifier:\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pratique, sklearn implémente des fonctions qui vont permettre de faciliter ce travai:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.swapaxes(0,1), y, test_size=72)\n",
    "X_train = X_train.swapaxes(0,1)\n",
    "X_test = X_test.swapaxes(0,1)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Ici on est obligé d'utiliser \"swapaxes\" car il faut que la première dimension de nos données soit la dimension qui liste les exemples. Or actuellement, la première dimentsion est la dimension des électrodes.\n",
    "\n",
    "Note2: Étant donné que le mélange des données est aléatoire, il est toujours possible par malchance d'avoir un split qui favorise une classe dans X_train et y_train, cela peut être contrôlé en utilisant une option de la fonction. Voir la doc: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "Note3: On obtient un mélange différent à chaque exécution du code. Le mélange peut être controllé si on désire pouvoir reproduire exactement la même expérience en fixant un \"random_state\". Voir doc: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évaluation du modèle\n",
    "\n",
    "Évaluons maintenant les performances de notre modèle sur notre problème. Ce qui nous intéresse, c'est de savoir quelle(s) électrode(s) permet le mieux de faire la différence entre stimuli gauche ou droite. Intéressons nous d'abord par la première de la liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrode = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînons le modèle sur le dataset d'entraînement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train[electrode], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et utilisons le modèle entraîné pour prédire les classes du dataset de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1\n",
      " 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test[electrode])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mesurer les performances de notre algorithme nous pouvons simplement calculer son erreur et sa précision: pour ce faire, il suffit de calculer erreur = Somme(valeur_absolue(y_pred - y_test)) / nombre_de_predictions\n",
    "\n",
    "puis accuracy = 1 - erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778\n"
     ]
    }
   ],
   "source": [
    "error = sum(abs(y_pred - y_test)) / len(y_pred)\n",
    "accuracy = 1 - error\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre score est de 52.8% de précision (accuracy). Il existe d'autres mesures de performance du modèle, mais dans notre cas, la précision est adaptée.\n",
    "\n",
    "Comme notre problème est un problème de classification binaire, le niveau de chance théorique est à 50%, cela veut dire que notre résultat est juste au dessus du niveau de chance et donc, que notre modèle est pas capable de faire la différence entre stimulus gauche et droite avec ces caractéristiques du signal là. \n",
    "\n",
    "Cependant, étant donné que nous avons un petit nombre de données, le niveau de chance théorique n'est pas le niveau de chance auquel on devrait comparer les performances de notre modèle. Il faut vérifier la pertinence statistique de ce résultat. Nous reviendrons sur cette partie plus tard.\n",
    "\n",
    "Pour voir plus de métriques de performances, voir <a href=\"https://en.wikipedia.org/wiki/Fairness_(machine_learning)\">ici</a>\n",
    "\n",
    "Encore une fois, en pratique il est beaucoup plus simple d'utiliser directement une fonction donnée par sklearn pour calculer la précision de notre modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(X_test[electrode], y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne nous reste donc plus qu'à répéter ces dernières opérations pour chaque électrode et de vérifier la pertinence statistique de nos résultats.\n",
    "\n",
    "Seulement, le problème de la \"Holdout method\" est que si on l'utilise sur un petit jeu de données, il est possible que cette séparation nous avantage ou désavantage dans l'évalutation des performances de notre algorithme par chance uniquement. Pour remédier à celà, on utilise des méthodes de \"cross-validation\". Une cross-validation va répéter le processus de découpage des donées plusieurs fois afin de limiter l'impact du facteur chance au minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "Voilà quelques méthodes de cross-validation communes:\n",
    "- Leave One Out (LOO)\n",
    "- Leave P Out (LPO)\n",
    "- K-Fold\n",
    "\n",
    "LOO consiste à laisser de côté un seul exemple de notre jeu de données pour le test et de garder tout le reste pour l'entraînement. Bien que cette méthode permette de mesurer avec précision la performance d'un algorithme, elle est rarement utilisée en pratique. En effet, cette méthode est exhaustive, ce qui veut dire qu'elle va essayer toutes les combinaisons prossibles de train et de test sets. Ce n'est pas un problème dans notre cas vu que notre jeu de données est relativement petit (seulement 140 exemples), mais cela peut devenir un problème quand on possède des millions d'exemples et que effectuer l'entrainement et le test de l'algorithme prend un certain temps.\n",
    "\n",
    "LPO est basée sur le même principe que LOO et est exhaustive. Cette méthode à l'avantage de tester sur plusieurs exemples au lieu d'un à chauque itération et est donc encore plus précise, mais elle souffre encore plus d'une augmentation de la taille des données, vu qu'il y a encore plus de combinaisons de p parmis n que de 1 parmis n.\n",
    "\n",
    "K-fold consiste à couper les données en K sous-parties, de combiner K-1 sous parties pour constituer le train set et d'utiliser la dernière sous partie comme test set. Cette méthode est souvent préférée puisque beaucoup plus rapide que les précédentes quand on à accès à beaucoup de données tout en donnant une idée acceptable de la performance de l'algorithme.\n",
    "\n",
    "Nous allons utiliser K-Fold puisque cette méthode est plus rapide tout en restant adaptée à notre problème.\n",
    "En pratique on utilise la verison \"stratifiée\"de K-Fold afin de s'asurer que chacune des sous-parties du dataset contient bien autant d'exemples de chaque condition. Sans cela, il serait possible par malchance d'avoir quelques sous-parties des données qui ne contiennent qu'une conditon, ce qui fausserai les résultats.\n",
    "\n",
    "On va choisir la valeur par défaut K = n_splits = 5, qui nous permettra d'avoir 5 scores de précision de notre algorithme entrainé sur K-1 = 4 / 5 = 80% de nos données et testé sur les 1/5 = 20% restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold as SKFold\n",
    "\n",
    "cv = SKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concrètement, ce que cette méthode va faire, c'est effectuer plusieures fois le train/test split que nous avons effectué plus haut manuellement.\n",
    "\n",
    "De cette façon, au lieu d'obtenir un score unique de précision pour une électrode, on peut en obtenir plusieurs et les moyenner afin d'avoir un résultat plus robuste. Si on effectue une étape de cross-validation avec notre objet cv, on peut reproduire ce qu'on a fait plus haut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in cv.split(electrode, targets):\n",
    "    X[electrode][train_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resultats = []\n",
    "for electrode in data:\n",
    "    predictions = []\n",
    "    for train_index, test_index in cv.split(electrode, targets):\n",
    "        clf = KNN()\n",
    "        clf.fit(electrode[train_index], targets[train_index])\n",
    "        pred = clf.predict(electrode[test_index])\n",
    "        predictions.append(pred)\n",
    "    resultats.append(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explication du code:\n",
    "\n",
    "Dans le code ci-dessus, on boucle à travers toutes les électrodes des données puis à travers toutes les instances de la cross-validation, en pseudo-code, ça donne:\n",
    "\n",
    "- créer une liste qui contiendra les résultats pour chaque électrode.\n",
    "- pour chaque électrode:\n",
    "    - créer une liste vide qui contiendra les prédictions pour cette électrode\n",
    "    - pour les K possibilitées de découpage des données:\n",
    "        - remettre à zero le classifieur \n",
    "        - entraîner le classifieur sur les K-1 sous parties\n",
    "        - tester le classifieur sur a sous-partie restante\n",
    "        - enregistrer les prédictions dans une liste\n",
    "    - enregistrer les prédictions de cette électrode dans la liste\n",
    "\n",
    "### Évaluation des performances du modèle\n",
    "\n",
    "Maintenant que le modèle a été testé pour chaque électrode avec la méthode de cross-validation choisie, explorons un peu les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305, 5)\n"
     ]
    }
   ],
   "source": [
    "# On convertie la liste des résultats en numpy array, un format plus facile à manipuler:\n",
    "resultats = np.array(resultats, dtype=object)\n",
    "\n",
    "# On vérifie que nos résultats ont bien la bonne dimension:\n",
    "print(resultats.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtiens une matrice de taille nombre_d_electrodes x nombres_de_folds. \n",
    "\n",
    "Affichons par exemple les performances de notre modèle sur la première électrode, sur le premier \"fold\" du K-Fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(resultats[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qu'on voit ci-dessus ce sont les prédictions individuelles pour les n examples qui ont été mis de côté lors de l'évaluation des performances de notre modèle sur le premier fold de la cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
